{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhanlp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中国人名识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[签约/vi, 仪式/n, 前/f, ，/w, 秦光荣/nr, 、/w, 李纪恒/nr, 、/w, 仇和/nr, 等/udeng, 一同/d, 会见/v, 了/ule, 参加/v, 签约/vi, 的/ude1, 企业家/nnt, 。/w]\n",
      "[武大靖/nr, 创/v, 世界/n, 纪录/n, 夺冠/vi, ，/w, 中国/ns, 代表团/n, 平昌/ns, 首/q, 金/b]\n",
      "[区长/nnt, 庄木弟/nr, 新年/t, 致辞/vi]\n",
      "[朱立伦/nr, ：/w, 两岸/n, 都/d, 希望/v, 共创/v, 双赢/n,  /w, 习/v, 朱/ag, 历史/n, 会晤/vn, 在即/vi]\n",
      "[陕西/ns, 首富/n, 吴一坚/nr, 被/pbei, 带走/v,  /w, 与/cc, 令计划/nr, 妻子/n, 有/vyou, 交集/v]\n",
      "[据/p, 美国之音/n, 电台/nis, 网站/n, 4月/t, 28/m, 日/b, 报道/v, ，/w, 8/m, 岁/qt, 的/ude1, 凯瑟琳·克罗尔/nrf, （/w, 凤甫娟/nr, ）/w, 和/cc, 很多/m, 华裔/n, 美国/nsf, 小朋友/n, 一样/uyy, ，/w, 小小/z, 年纪/n, 就/d, 开始/v, 学/v, 小提琴/n, 了/ule, 。/w, 她/rr, 的/ude1, 妈妈/n, 是/vshi, 位/q, 虎妈/nz, 么/y, ？/w]\n",
      "[凯瑟琳/nrf, 和/cc, 露西/nrf, （/w, 庐瑞媛/nr, ）/w, ，/w, 跟/p, 她们/rr, 的/ude1, 哥哥/n, 们/k, 有/vyou, 一些/m, 不同/a, 。/w]\n",
      "[王国强/nr, 、/w, 高峰/n, 、/w, 汪洋/n, 、/w, 张朝阳/nr, 光/n, 着/uzhe, 头/n, 、/w, 韩寒/nr, 、/w, 小/a, 四/m]\n",
      "[张浩/nr, 和/cc, 胡健康/nr, 复员/v, 回家/vi, 了/ule]\n",
      "[王总/nr, 和/cc, 小丽/nr, 结婚/vi, 了/ule]\n",
      "[编剧/nnt, 邵钧林/nr, 和/cc, 稽道青/nr, 说/v]\n",
      "[这里/rzs, 有/vyou, 关天培/nr, 的/ude1, 有关/vn, 事迹/n]\n",
      "[龚学平/nr, 等/udeng, 领导/n, 说/v, ,/w, 邓颖超/nr, 生前/t, 杜绝/v, 超生/vi]\n"
     ]
    }
   ],
   "source": [
    "# 中国人名识别\n",
    "sentences = [\n",
    "    \"签约仪式前，秦光荣、李纪恒、仇和等一同会见了参加签约的企业家。\",\n",
    "    \"武大靖创世界纪录夺冠，中国代表团平昌首金\",\n",
    "    \"区长庄木弟新年致辞\",\n",
    "    \"朱立伦：两岸都希望共创双赢 习朱历史会晤在即\",\n",
    "    \"陕西首富吴一坚被带走 与令计划妻子有交集\",\n",
    "    \"据美国之音电台网站4月28日报道，8岁的凯瑟琳·克罗尔（凤甫娟）和很多华裔美国小朋友一样，小小年纪就开始学小提琴了。她的妈妈是位虎妈么？\",\n",
    "    \"凯瑟琳和露西（庐瑞媛），跟她们的哥哥们有一些不同。\",\n",
    "    \"王国强、高峰、汪洋、张朝阳光着头、韩寒、小四\",\n",
    "    \"张浩和胡健康复员回家了\",\n",
    "    \"王总和小丽结婚了\",\n",
    "    \"编剧邵钧林和稽道青说\",\n",
    "    \"这里有关天培的有关事迹\",\n",
    "    \"龚学平等领导说,邓颖超生前杜绝超生\",\n",
    "]\n",
    "segment = HanLP.newSegment().enableNameRecognize(True)\n",
    "for sentence in sentences:\n",
    "    term_list = segment.seg(sentence)\n",
    "    print(term_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 音译人名识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[一桶/nz, 冰水/n, 当头/vi, 倒下/v, ，/w, 微软/ntc, 的/ude1, 比尔盖茨/nrf, 、/w, Facebook/nx, 的/ude1, 扎克伯格/nrf, 跟/p, 桑德博格/nrf, 、/w, 亚马逊/nrf, 的/ude1, 贝索斯/nrf, 、/w, 苹果/nf, 的/ude1, 库克/nrf, 全都/d, 不惜/v, 湿身/nz, 入镜/nz, ，/w, 这些/rz, 硅谷/ns, 的/ude1, 科技/n, 人/n, ，/w, 飞蛾/n, 扑火/vn, 似/vg, 地/ude2, 牺牲/v, 演出/vn, ，/w, 其实/d, 全/a, 为了/p, 慈善/a, 。/w]\n",
      "[世界/n, 上/f, 最长/d, 的/ude1, 姓名/n, 是/vshi, 简森·乔伊·亚历山大·比基·卡利斯勒·达夫·埃利奥特·福克斯·伊维鲁莫·马尔尼·梅尔斯·帕特森·汤普森·华莱士·普雷斯顿/nrf, 。/w]\n"
     ]
    }
   ],
   "source": [
    "# 音译人名识别\n",
    "sentences = [\n",
    "    \"一桶冰水当头倒下，微软的比尔盖茨、Facebook的扎克伯格跟桑德博格、亚马逊的贝索斯、苹果的库克全都不惜湿身入镜，这些硅谷的科技人，飞蛾扑火似地牺牲演出，其实全为了慈善。\",\n",
    "    \"世界上最长的姓名是简森·乔伊·亚历山大·比基·卡利斯勒·达夫·埃利奥特·福克斯·伊维鲁莫·马尔尼·梅尔斯·帕特森·汤普森·华莱士·普雷斯顿。\",\n",
    "]\n",
    "segment = HanLP.newSegment().enableTranslatedNameRecognize(True)\n",
    "for sentence in sentences:\n",
    "    term_list = segment.seg(sentence)\n",
    "    print(term_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日本人名识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[北川景子/nrj, 参演/v, 了/ule, 林诣彬/nr, 导演/nnt, 的/ude1, 《/w, 速度/n, 与/cc, 激情/n, 3/m, 》/w]\n",
      "[林志玲/nr, 亮相/vi, 网友/n, :/w, 确定/v, 不是/c, 波多野结衣/nrj, ？/w]\n",
      "[龟山千广/nrj, 和/cc, 近藤公园/nrj, 在/p, 龟山/nz, 公园/n, 里/f, 喝酒/vi, 赏花/nz]\n"
     ]
    }
   ],
   "source": [
    "# 日本人名识别\n",
    "sentences = [\n",
    "    \"北川景子参演了林诣彬导演的《速度与激情3》\",\n",
    "    \"林志玲亮相网友:确定不是波多野结衣？\",\n",
    "    \"龟山千广和近藤公园在龟山公园里喝酒赏花\",\n",
    "]\n",
    "Segment = JClass(\"com.hankcs.hanlp.seg.Segment\")\n",
    "Term = JClass(\"com.hankcs.hanlp.seg.common.Term\")\n",
    "\n",
    "segment = HanLP.newSegment().enableJapaneseNameRecognize(True)\n",
    "for sentence in sentences:\n",
    "    term_list = segment.seg(sentence)\n",
    "    print(term_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 地名识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[蓝翔/nr, 给/p, 宁夏/ns, 固原市/ns, 彭阳县/ns, 红河镇/ns, 黑牛沟村/ns, 捐赠/v, 了/ule, 挖掘机/n]\n"
     ]
    }
   ],
   "source": [
    "# 地名识别\n",
    "sentences = [\"蓝翔给宁夏固原市彭阳县红河镇黑牛沟村捐赠了挖掘机\"]\n",
    "Segment = JClass(\"com.hankcs.hanlp.seg.Segment\")\n",
    "Term = JClass(\"com.hankcs.hanlp.seg.common.Term\")\n",
    "\n",
    "segment = HanLP.newSegment().enablePlaceRecognize(True)\n",
    "for sentence in sentences:\n",
    "    term_list = segment.seg(sentence)\n",
    "    print(term_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机构名识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[我/rr, 在/p, 上海/ns, 林原科技有限公司/nt, 兼职/vn, 工作/vn, ，/w]\n",
      "[我/rr, 经常/d, 在/p, 台川喜宴餐厅/nt, 吃饭/vi, ，/w]\n",
      "[偶尔/d, 去/vf, 开元地中海影城/nt, 看/v, 电影/n, 。/w]\n"
     ]
    }
   ],
   "source": [
    "# 机构名识别\n",
    "sentences = [\n",
    "    \"我在上海林原科技有限公司兼职工作，\",\n",
    "    \"我经常在台川喜宴餐厅吃饭，\",\n",
    "    \"偶尔去开元地中海影城看电影。\",\n",
    "]\n",
    "Segment = JClass(\"com.hankcs.hanlp.seg.Segment\")\n",
    "Term = JClass(\"com.hankcs.hanlp.seg.common.Term\")\n",
    "\n",
    "segment = HanLP.newSegment().enableOrganizationRecognize(True)\n",
    "for sentence in sentences:\n",
    "    term_list = segment.seg(sentence)\n",
    "    print(term_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演示数词和数量词识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[十九元/mq, 套餐/n, 包括/v, 什么/ry]\n",
      "[九千九百九十九朵/mq, 玫瑰/n]\n",
      "[壹佰块/mq, 都/d, 不/d, 给/p, 我/rr]\n",
      "[９０１２３４５６７８只/mq, 蚂蚁/n]\n",
      "[牛奶/nf, 三〇〇克/mq, */w, 2/m]\n",
      "[ChinaJoy/nx, “/w, 扫黄/vi, ”/w, 细则/n, 露/v, 胸/ng, 超/v, 2厘米/mq, 罚款/vi]\n"
     ]
    }
   ],
   "source": [
    "# 演示数词和数量词识别\n",
    "sentences = [\n",
    "    \"十九元套餐包括什么\",\n",
    "    \"九千九百九十九朵玫瑰\",\n",
    "    \"壹佰块都不给我\",\n",
    "    \"９０１２３４５６７８只蚂蚁\",\n",
    "    \"牛奶三〇〇克*2\",\n",
    "    \"ChinaJoy“扫黄”细则露胸超2厘米罚款\",\n",
    "]\n",
    "StandardTokenizer = JClass(\"com.hankcs.hanlp.tokenizer.StandardTokenizer\")\n",
    "\n",
    "StandardTokenizer.SEGMENT.enableNumberQuantifierRecognize(True)\n",
    "for sentence in sentences:\n",
    "    print(StandardTokenizer.segment(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演示URL识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HanLP/nx, 的/ude1, 项目/n, 地址/n, 是/vshi, https://github.com/hankcs/HanLP/xu, ，/w, \n",
      "/w, 发布/v, 地址/n, 是/vshi, https://github.com/hankcs/HanLP/releases/xu, ，/w, \n",
      "/w, 我/rr, 有时候/d, 会/v, 在/p, www.hankcs.com/xu, 上面/f, 发布/v, 一些/m, 消息/n, ，/w, \n",
      "/w, 我/rr, 的/ude1, 微博/n, 是/vshi, http://weibo.com/hankcs//xu, ，/w, 会/v, 同步/vd, 推送/nz, hankcs.com/xu, 的/ude1, 新闻/n, 。/w, \n",
      "/w, 听说/v, ./w, 中国/ns, 域名/n, 开放/v, 申请/v, 了/ule, ,/w, 但/c, 我/rr, 并/cc, 没有/v, 申请/v, hankcs.中国/xu, ,/w, 因为/c, 穷/a, ……/w, \n",
      "/w]\n",
      "https://github.com/hankcs/HanLP\n",
      "https://github.com/hankcs/HanLP/releases\n",
      "www.hankcs.com\n",
      "http://weibo.com/hankcs/\n",
      "hankcs.com\n",
      "hankcs.中国\n"
     ]
    }
   ],
   "source": [
    "# 演示URL识别\n",
    "text = '''HanLP的项目地址是https://github.com/hankcs/HanLP，\n",
    "发布地址是https://github.com/hankcs/HanLP/releases，\n",
    "我有时候会在www.hankcs.com上面发布一些消息，\n",
    "我的微博是http://weibo.com/hankcs/，会同步推送hankcs.com的新闻。\n",
    "听说.中国域名开放申请了,但我并没有申请hankcs.中国,因为穷……\n",
    "'''\n",
    "Nature = JClass(\"com.hankcs.hanlp.corpus.tag.Nature\")\n",
    "Term = JClass(\"com.hankcs.hanlp.seg.common.Term\")\n",
    "URLTokenizer = JClass(\"com.hankcs.hanlp.tokenizer.URLTokenizer\")\n",
    "\n",
    "term_list = URLTokenizer.segment(text)\n",
    "print(term_list)\n",
    "for term in term_list:\n",
    "    if term.nature == Nature.xu:\n",
    "        print(term.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
