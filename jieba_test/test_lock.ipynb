{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inittokenizer(tokenizer, group):\n",
    "    print('===> Thread %s:%s started' % (group, threading.current_thread().ident))\n",
    "    tokenizer.initialize()\n",
    "    print('<=== Thread %s:%s finished' % (group, threading.current_thread().ident))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Building prefix dict from E:\\PythonProjects\\chinese_word_segmentation_test\\jieba_test\\extra_dict\\dict.txt.small ...\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Jacen\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model from cache C:\\Users\\Jacen\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Thread 1:14460 started\n",
      "===> Thread 1:11408 started\n",
      "===> Thread 1:10288 started\n",
      "===> Thread 1:9288 started===> Thread 1:7652 started\n",
      "\n",
      "===> Thread 2:2020 started\n",
      "===> Thread 2:2732 started\n",
      "===> Thread 2:2796 started===> Thread 2:14668 started\n",
      "\n",
      "===> Thread 2:12640 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from cache C:\\Users\\Jacen\\AppData\\Local\\Temp\\jieba.cache\n",
      "Building prefix dict from E:\\PythonProjects\\chinese_word_segmentation_test\\jieba_test\\extra_dict\\dict.txt.small ...\n",
      "Loading model from cache C:\\Users\\Jacen\\AppData\\Local\\Temp\\jieba.cache\n",
      "Building prefix dict from E:\\PythonProjects\\chinese_word_segmentation_test\\jieba_test\\extra_dict\\dict.txt.small ...\n",
      "Building prefix dict from E:\\PythonProjects\\chinese_word_segmentation_test\\jieba_test\\extra_dict\\dict.txt.small ...\n",
      "Building prefix dict from E:\\PythonProjects\\chinese_word_segmentation_test\\jieba_test\\extra_dict\\dict.txt.small ...\n",
      "Loading model from cache C:\\Users\\Jacen\\AppData\\Local\\Temp\\jieba.cache\n",
      "Dumping model to file cache C:\\Users\\Jacen\\AppData\\Local\\Temp\\jieba.ub962b1c15aa6e517cd2afe8f31bd04cf.cache\n",
      "Loading model cost 2.079 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<=== Thread 2:2020 finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache C:\\Users\\Jacen\\AppData\\Local\\Temp\\jieba.ub962b1c15aa6e517cd2afe8f31bd04cf.cache\n",
      "Loading model cost 6.538 seconds.\n",
      "Loading model cost 6.575 seconds.\n",
      "Loading model cost 6.508 seconds.\n",
      "Loading model cost 6.615 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "Prefix dict has been built succesfully.\n",
      "Prefix dict has been built succesfully.\n",
      "Prefix dict has been built succesfully.\n",
      "Loading model cost 6.438 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<=== Thread 1:10288 finished\n",
      "<=== Thread 1:11408 finished\n",
      "<=== Thread 1:7652 finished\n",
      "<=== Thread 1:14460 finished\n",
      "<=== Thread 2:2732 finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache C:\\Users\\Jacen\\AppData\\Local\\Temp\\jieba.ub962b1c15aa6e517cd2afe8f31bd04cf.cache\n",
      "Loading model cost 7.543 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "Loading model cost 7.152 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<=== Thread 1:9288 finished\n",
      "<=== Thread 2:2796 finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache C:\\Users\\Jacen\\AppData\\Local\\Temp\\jieba.ub962b1c15aa6e517cd2afe8f31bd04cf.cache\n",
      "Loading model cost 7.493 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<=== Thread 2:14668 finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dumping model to file cache C:\\Users\\Jacen\\AppData\\Local\\Temp\\jieba.ub962b1c15aa6e517cd2afe8f31bd04cf.cache\n",
      "Loading model cost 7.926 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<=== Thread 2:12640 finished\n"
     ]
    }
   ],
   "source": [
    "tokrs1 = [jieba.Tokenizer() for n in range(5)]\n",
    "tokrs2 = [jieba.Tokenizer('./extra_dict/dict.txt.small') for n in range(5)]\n",
    "\n",
    "thr1 = [threading.Thread(target=inittokenizer, args=(tokr, 1)) for tokr in tokrs1]\n",
    "thr2 = [threading.Thread(target=inittokenizer, args=(tokr, 2)) for tokr in tokrs2]\n",
    "for thr in thr1:\n",
    "    thr.start()\n",
    "for thr in thr2:\n",
    "    thr.start()\n",
    "for thr in thr1:\n",
    "    thr.join()\n",
    "for thr in thr2:\n",
    "    thr.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Jacen\\AppData\\Local\\Temp\\jieba.cache\n",
      "Building prefix dict from E:\\PythonProjects\\chinese_word_segmentation_test\\jieba_test\\extra_dict\\dict.txt.small ...\n",
      "Loading model from cache C:\\Users\\Jacen\\AppData\\Local\\Temp\\jieba.ub962b1c15aa6e517cd2afe8f31bd04cf.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Thread 1:6496 started\n",
      "===> Thread 1:15128 started===> Thread 1:13088 started\n",
      "\n",
      "===> Thread 1:14016 started===> Thread 1:9572 started\n",
      "===> Thread 2:3052 started\n",
      "===> Thread 2:14664 started\n",
      "===> Thread 2:6008 started\n",
      "===> Thread 2:12296 started\n",
      "\n",
      "===> Thread 2:10536 started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.689 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<=== Thread 2:14664 finished<=== Thread 2:3052 finished<=== Thread 2:12296 finished\n",
      "\n",
      "<=== Thread 2:6008 finished\n",
      "<=== Thread 2:10536 finished\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 1.708 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<=== Thread 1:6496 finished\n",
      "<=== Thread 1:15128 finished<=== Thread 1:13088 finished\n",
      "\n",
      "<=== Thread 1:14016 finished<=== Thread 1:9572 finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "del tokrs1, tokrs2\n",
    "\n",
    "tokr1 = jieba.Tokenizer()\n",
    "tokr2 = jieba.Tokenizer('./extra_dict/dict.txt.small')\n",
    "\n",
    "thr1 = [threading.Thread(target=inittokenizer, args=(tokr1, 1)) for n in range(5)]\n",
    "thr2 = [threading.Thread(target=inittokenizer, args=(tokr2, 2)) for n in range(5)]\n",
    "for thr in thr1:\n",
    "    thr.start()\n",
    "for thr in thr2:\n",
    "    thr.start()\n",
    "for thr in thr1:\n",
    "    thr.join()\n",
    "for thr in thr2:\n",
    "    thr.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
